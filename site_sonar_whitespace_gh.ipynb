{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import base64\n",
    "from itertools import combinations\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_sonar_csv = 'https://dl.dropboxusercontent.com/s/yax3qabtyqy9q7p/site_sonar.csv'\n",
    "dist_threshold = 100           # To keep, a location needs to be 100+ miles away from the next closest location\n",
    "prediction_threshold = 250000  # To keep, a location needs to be predicted to make $250,000+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_link(df, title = \"Download Whitespace Analysis CSV\", filename = \"whitespace_results.csv\"):      \n",
    "    \"\"\"Create a link to download a DataFrame as a CSV file.  Limited to files ~2MB or less.\n",
    "    \n",
    "    Taken from: https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel\n",
    "    \"\"\"\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# Originally used geopy for this, but avoiding that dependency\n",
    "def distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    origin : tuple of float\n",
    "        (lat, long)\n",
    "    destination : tuple of float\n",
    "        (lat, long)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_in_km : float\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> origin = (48.1372, 11.5756)  # Munich\n",
    "    >>> destination = (52.5186, 13.4083)  # Berlin\n",
    "    >>> round(distance(origin, destination), 1)\n",
    "    504.2\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_next_biggest_conflict(loc_pairs, prediction_threshold):\n",
    "    \"\"\"Finds the coordinates of the location that should be dropped next.\n",
    "    \n",
    "    Using a DataFrame generated by all_location_pairs, returns the coordinates of\n",
    "    the location in that DataFrame that has the most violations of the distance\n",
    "    threshold and the lowest predicted revenue.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the set of locations with the most conflicts\n",
    "    maxcount_conflicts = loc_pairs.loc1_coords.value_counts()\n",
    "    maxcount_conflicts = maxcount_conflicts[maxcount_conflicts == max(maxcount_conflicts)]  \n",
    "\n",
    "    # Of those, find the one with the lowest predicted revenue, and return it.\n",
    "    drop_coords = None\n",
    "    drop_prediction = math.inf\n",
    "    for coords, count in maxcount_conflicts.iteritems():\n",
    "        prediction = site_sonar_predictions[coords]\n",
    "        if prediction < drop_prediction:\n",
    "            drop_prediction = prediction\n",
    "            drop_coords = coords\n",
    "\n",
    "    return drop_coords\n",
    "\n",
    "def km_to_mi(km):\n",
    "    # 1 km == 0.621371mi\n",
    "    # 1 mi == 1.60934km\n",
    "    miles = round(km * 0.621371, 2)\n",
    "    return miles # returning value into main code\n",
    "\n",
    "def make_coords_tuple(row):\n",
    "    \"\"\"Given a DataFrame row that contains Latitude & Longitude columns, returns those coordinates as a tuple.\"\"\"\n",
    "    return (row['Latitude'], row['Longitude'])\n",
    "\n",
    "def tooclose_location_pairs(loc_coords, loc_predictions, dist_threshold):\n",
    "    \"\"\"Given a Series of location coordinate tuples, creates a DataFrame of location pairs below the distance threshold.\n",
    "    \n",
    "    Each location pair (loc1, loc2) below the threshold will be listed twice; once with loc1 listed first, and again\n",
    "    with loc2 listed first.\n",
    "    \"\"\"\n",
    "    \n",
    "    tooclose_pairs = {}\n",
    "    i = 0\n",
    "    \n",
    "    for pair in combinations(loc_coords, 2):\n",
    "        startloc_coords = pair[0]\n",
    "        endloc_coords = pair[1]\n",
    "\n",
    "        dist = km_to_mi(distance(startloc_coords, endloc_coords))\n",
    "        \n",
    "        if (dist < dist_threshold):\n",
    "            tooclose_pairs[i] = {\n",
    "                'loc1_coords'     : startloc_coords,\n",
    "                'loc2_coords'     : endloc_coords,\n",
    "                'distance'        : dist,\n",
    "                'loc1_prediction' : loc_predictions[startloc_coords]\n",
    "            }\n",
    "            tooclose_pairs[i] = {\n",
    "                'loc1_coords'     : endloc_coords,\n",
    "                'loc2_coords'     : startloc_coords,\n",
    "                'distance'        : dist,\n",
    "                'loc1_prediction' : loc_predictions[endloc_coords]\n",
    "            }\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "    return pd.DataFrame.from_dict(tooclose_pairs, \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Site Sonar data\n",
    "site_sonar = pd.read_csv(site_sonar_csv)\n",
    "\n",
    "print(\"Number of locations from original Site Sonar data:\")\n",
    "print(len(site_sonar))\n",
    "\n",
    "print(\"Details of locations from original Site Sonar data:\")\n",
    "site_sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subset of with a predicted revenue below our threshold\n",
    "site_sonar = site_sonar[site_sonar['Total Zeustimate'] > prediction_threshold]\n",
    "\n",
    "site_sonar_coords = site_sonar.apply(lambda row: make_coords_tuple(row), axis=1)\n",
    "site_sonar_predictions = dict(zip(site_sonar_coords, site_sonar['Total Zeustimate']))\n",
    "\n",
    "print(\"Number of locations meeting the prediction constraint:\")\n",
    "print(len(site_sonar))\n",
    "\n",
    "print(\"Details of locations meeting the prediction constraint:\")\n",
    "site_sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing pairs of locations violating the distance constraint, and the distances between them.\n",
    "tooclose_pairs = tooclose_location_pairs(site_sonar_coords, site_sonar_predictions, dist_threshold)\n",
    "\n",
    "print(\"Number of location pairs (symmetric) violating the distance constraint:\")\n",
    "print(len(tooclose_pairs))\n",
    "\n",
    "print(\"Details of location pairs (symmetric) violating the distance constraint:\")\n",
    "tooclose_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the \"too close\" pairs. At each step, drop the next-biggest\n",
    "# violation of our distance and revenue constraints.\n",
    "while not tooclose_pairs.empty: \n",
    "    drop_coords = get_next_biggest_conflict(tooclose_pairs, prediction_threshold)\n",
    "    \n",
    "    tooclose_pairs = tooclose_pairs[tooclose_pairs.loc1_coords != drop_coords]\n",
    "    tooclose_pairs = tooclose_pairs[tooclose_pairs.loc2_coords != drop_coords]\n",
    "    \n",
    "    site_sonar_coords = site_sonar_coords[site_sonar_coords != drop_coords]\n",
    "    site_sonar_predictions.pop(drop_coords)\n",
    "    site_sonar = site_sonar[ (site_sonar.Latitude != drop_coords[0]) | (site_sonar.Longitude != drop_coords[1]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of locations meeting both prediction and distance constraints:\")\n",
    "print(len(site_sonar))\n",
    "\n",
    "print(\"Details of locations meeting both prediction and distance constraints:\")\n",
    "site_sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If writing a local file:\n",
    "#\n",
    "# path, filename = os.path.split(site_sonar_csv)\n",
    "# filename = os.path.splitext(filename)[0]\n",
    "# newfilename = '%s_whitespace_recommendations.csv' % filename\n",
    "# keep_csv = os.path.join(path, newfilename)\n",
    "# site_sonar.to_csv(keep_csv, index=False)\n",
    "\n",
    "create_download_link(site_sonar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sonar_whitespace]",
   "language": "python",
   "name": "conda-env-sonar_whitespace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
